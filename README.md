# TextCorrector
## НГУ. ФФ. Физическая информатика
### Структурное программирование. 3 семестр. Проект
### TextCorrector
Программа для поиска и исправления орфографических ошибок в тексте. Работает с файлами формата `.txt`
#### Что делает:
- Программа для редактирования текста.
- Работа через консоль.
- В параметрах при запуске передаётся путь к редактируемому файлу.
- Отредактированный файл сохраняется под требуемым именем.
#### Как делает:
- В основе лежит модель, запоминающая существующие слова по набору текстов на этапе обучения.
- При редактировании текста заменяет незнакомые слова в тексте на максимально похожие выученные. (см. далее)

__WARNING: ИМЕНА ФАЙЛОВ НЕ ДОЛЖНЫ СОДЕРЖАТЬ `_temporary_file__`, ИНАЧЕ ОНИ МОГУТ БЫТЬ УДАЛЕНЫ!!!__

Слова хранятся в хеш-таблицах. Каждая хеш-таблица хранит слова одной и той же длины. Коллизии решаются с использованием связных списков. На этапе обучения слова, содержащие символы, кроме русских и английских букв, не запоминаются.

- Редактирование:

Слова длины 1 не заменяются! Т.к. пользователь может захотеть написать любой неосмысленный символ

Первоначально при редактировании слова алгоритм проверяет в таблице со словами соответствующей длины, существует ли такое слово. Если находит, то ничего не меняет. 

Именно это и подтверждает разумность использования хеш-таблиц. Во-первых, вставка элемента практически за O(1) (немного больше, т.к. возможны коллизии), а на этапе обучения нам нужно вставлять много слов. Во-вторых, предполагается, что большинство слов в редактируемом тексте всё же будут написаны правильно, поэтому желательно быстро уметь находить их среди изученных. Хеш-таблица позволяет сделать это также за O(1) (с поправкой на коллизии). Если же слово не нашлось, то придётся перебирать все возможные варианты замены. В таком случае любая структура будет осуществлять поиск примерно за O(N).

Если же такого слова нет, то нужно найти максимально "близкое" слово. Алгоритм проходит по таблицам изученных слов такой же длины +-`size_tol` (максимально допустимое отклонение в длине слова, нужно задать в параметрах) и для каждого варианта считает отклонение от заменяемого слова. Из всех слов выбирается то, которое имеет минимальное отклонение. При этом если, например, найдено слово такой же длины, но с отклонением на 1 букву, то точно нет смысла искать совпадения среди слов, отличающихся на 2 буквы, даже если size_tol > 1.

- Отклонение:

Отклонение считается как количество различающихся букв в соответствующих позициях (расстояние Хэмминга). При этом если минимальное отклонение больше, чем заданный параметр `threshold`, то слово также остаётся без изменений, т.к. ему не удалось подобрать адекватную замену. На этапе обучения  и редактирования для каждого слова подсчитывается количество раз, которое оно встретилось. Это значение хранится в списке вместе с самим словом. Если два или более слов имеют одинаковое отклонение от заменяемое, то слово выбирается наиблее часто встречающееся. Если таких несколько - выбирается первое встретившееся при сравнении.

- Регистр:

Все слова хранятся в нижнем регистре, поэтому исправление маленьких букв на заглавные в именах собственных не предусмотрена. Слова сравниваются без учёта регистра. Если в ИЗУЧАЕМОМ слове есть заглавные буквы, слово всё равно сохраняется со всеми маленькими. Если в РЕДАКТИРУЕМОМ слове более одной заглавной буквы, то предполагается, что это какое-то сокращение или аббревиатура, и слово остаётся без изменений (т.к. невозможно догадаться, что "зашифровал" пользователь"). Если заглавная буква одна и она не первая, то она в любом случае заменяется на прописную. Если заглавная буква первая, то отредактированное слово тоже будет с заглавной буквы.

- Небуквенные символы в слове:
Небуквенный символ может возникнуть по четырём причинам: 
1. дефис в слове
2. знаки препинания после слова пишутся с ним слитно
3. пользователь написал слово, поставил знак препинания и забыл поставить пробел перед следующим словом
4. пользователь вместо буквы написал знак препинания
Первые два случая - нормальные, третий  и четвёртый - ошибки. Т.к. обучение происходит на текстах, которым пользователь доверяет, то предполагается, что там нет ошибок. Поэтому если последний символ небуквенный, то он просто отбрасывается при ОБУЧЕНИИ. Если же небуквенный символ в середине или в начале, то если это дефис, то слово запоминается целиком, а если другой символ, то не запоминается (не запоминаем числа, даты и тп). Если небуквенный символ встречается на этапе РЕДАКТИРОВАНИЯ, то сначала проверяем его наличие в словаре. Если такого слова нет, то производим две попытки редактирования. Сначала слово разбивается на токены всеми небуквенными символами и пробуем заменить каждое слово в отдельности. Если каждый токен оказался либо изученным, либо получилось его заменить (т.е. нет токенов, в которых слишком много ошибок), то считаем СУММАРНОЕ отклонение и СРЕДНЕЕ количество встреч таких токенов на этапе обучения. Далее пробуем заменить всё слово целиком, вместе с небуквенными символами. Из двух вариантов лучшим считается тот, у которого меньше суммарное отклонение. Если отклонение одинаковое, то встречается средняя встречаемость при обучении. Если лучшим оказывается вариант с токенами, то при редактировании небуквенные символы остаются и пишутся в конце каждого токена (ошибка_3 пользователя). Если лучшим оказывается полная замена, то небуквенные символы не пишутся (ошибка_4 пользователя).

#### Параметры, определение конфигурации работы программы
ВСЕ ПАРАМЕТРЫ ДОЛЖНЫ БЫТЬ РАЗДЕЛЕНЫ ПРОБЕЛАМИ!

ДВОЙНЫЕ кавычки позволительны (даже обязательны, если параметр - это некоторый путь, содержащий пробелы). Если параметр написан без кавычек - он читается до первого пробела. Если параметр в двойных кавычках - он читается от открывающей до закрывающей кавычки.

Первый параметр при запуске - режим ввода конфигурации
1. `params`
2. `step_by_step` (если параметров нет, то запускается также этот режим)
3. `from_file`
4. `help` - вывести справку
- В режиме `params` вся конфигурация должна быть задана в параметрах вызова
- В режиме `step_by_step` больше никаких параметров нет, по крайней мере мы их не обрабатываем. Пользователя последовательно просят ввести все параметры в консоль. Пользователю даются некоторые пояснения и несколько попыток корректно ввести требуемые параметры конфигурации
- В режиме `from_file` единственный следующий параметр - путь к файлу с конфигурацией (чтобы каждый раз не вводить параметры). __Имя файла не должно содержать `_temporary_file__`, иначе он может быть удалён!!!__

Далее надо определиться с режимом работы:
- `train_new` - обучение новой модели
- `train_existed` - дообучение существующей модели
- `edit` - редактирование текста

В режиме `train_new` нужны:
- путь для сохранения модели в формате __*.txt__ (вместе с новым именем)
- путь к обучающему тексту в формате __*.txt__
- максимальная длина запоминаемых слов (`max_word_size`). От 1 до 35

В режиме `train_existed` нужны:
- путь к существующей модели в формате __*.txt__
- путь к обучающему тексту в формате __*.txt__

В режиме `edit` нужны:
- путь к обученной модели в формате __*.txt__
- путь к редактируемому файлу в формате __*.txt__
- путь для сохранения отредактированного файла в формате __*.txt__ (вместе с новым именем)
- максимально допустимое отклонение длины заменяющего слова от заменяемого (`size_tol`). От 0 до 3
- максимально допустимая разность слов (`threshold`). Если разница для минимально отличающегося слова превышает этот порог, то слово остаётся в тексте без изменений (не удалось подобрать адекватную замену). От 0 до 3

#### Как выглядит окончательный конфиг
В режиме `train_new`:
1. Метка режима, 0, тип int
2. Путь для сохранения новой модели, строка (char*)
3. Путь к обучающему тексту, строка (char*)
4. Максимальная длина запоминаемых слов (`max_word_length`)

В режиме `train_existed` (т.к. модель существующая, то параметр `max_word_length` был задан ранее и записан в файл с моделью; он будет установлен при чтении модели из файла, в cfg его писать не нужно):
1. Метка режима, 1, тип int
2. Путь к существующей модели, строка (char*)
3. Путь к обучающему тексту, строка (char*)

В режиме `edit`:
1. Метка режима, 2, тип int
2. Путь к обученной модели
3. Путь к редактируемому тексту
4. Путь для сохранения отредактированного текста (путь вместе с именем)
5. Максимально допустимое отклонение длины заменяющего слова от заменяемого (`size_tol`)
6. Максимально допустимая разность слов (`threshold`)


